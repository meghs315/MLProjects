{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUtz-SqPVUju"
   },
   "source": [
    "## **Power Plant Regression (Customized + Outliers)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe and test/train splits of the original data w/ outliers.\n",
    "DATA_PATH = \"usina_with_outliers.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "X = df.drop(\"PE\", axis=1)\n",
    "y = df[\"PE\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFetI3C6VeW0"
   },
   "source": [
    "## Question 1: ##\n",
    "**Model Choice and Justification**: I chose Linear Regression (OLS) because Cook’s Distance was derived specifically for use with OLS models. Ridge and Lasso apply coefficient shrinkage, which can reduce the apparent influence of individual observations. Since the goal of this task is to identify and remove influential outliers, using OLS preserves the full influence structure of the data and makes Cook’s Distance more interpretable.\n",
    "\n",
    "I chose Statsmodels because it is designed for statistical inference and provides built-in influence diagnostics, including Cook’s Distance. This allows Cook’s Distance to be computed directly from the OLS model without requiring manual implementation, ensuring more correct outlier detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train)\n",
    "\n",
    "# Fit OLS for Statsmodel\n",
    "ols_model = sm.OLS(y_train, X_train_sm).fit()\n",
    "\n",
    "# Get Cook's Distance\n",
    "influence = ols_model.get_influence()\n",
    "cooks_d = influence.cooks_distance[0]\n",
    "\n",
    "# Create DataFrame for Cook's Distance\n",
    "cooks_df = pd.DataFrame({\n",
    "    \"CookD\": cooks_d\n",
    "}, index=X_train.index)\n",
    "\n",
    "# Threshold for removing outliers. \n",
    "n = X_train_sm.shape[0]\n",
    "threshold = 4 / n\n",
    "\n",
    "# Identify outlier indices\n",
    "outlier_indices = cooks_df[cooks_df[\"CookD\"] > threshold].index\n",
    "\n",
    "# Create clean DF \n",
    "df_clean = df.drop(index=outlier_indices)\n",
    "\n",
    "df_clean.to_csv(\"usina.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, model_name, alpha=None):\n",
    "    \"\"\"Returns MSE, MAE, R^2 information for given model.\"\"\"\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred  = model.predict(X_test)\n",
    "    \n",
    "    return {\n",
    "        \"Model\": f\"{model_name}\" if alpha is None else f\"{model_name} (alpha={alpha})\",\n",
    "        \"Train MSE\": mean_squared_error(y_train, y_train_pred),\n",
    "        \"Train MAE\": mean_absolute_error(y_train, y_train_pred),\n",
    "        \"Train R^2\": r2_score(y_train, y_train_pred),\n",
    "        \"Test MSE\": mean_squared_error(y_test, y_test_pred),\n",
    "        \"Test MAE\": mean_absolute_error(y_test, y_test_pred),\n",
    "        \"Test R^2\": r2_score(y_test, y_test_pred)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models trained w/ Outliers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Train R^2</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>123.384207</td>\n",
       "      <td>5.198679</td>\n",
       "      <td>0.650171</td>\n",
       "      <td>125.113389</td>\n",
       "      <td>5.052458</td>\n",
       "      <td>0.642574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge (alpha=0.01)</td>\n",
       "      <td>123.384207</td>\n",
       "      <td>5.198679</td>\n",
       "      <td>0.650171</td>\n",
       "      <td>125.113389</td>\n",
       "      <td>5.052458</td>\n",
       "      <td>0.642574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge (alpha=0.1)</td>\n",
       "      <td>123.384207</td>\n",
       "      <td>5.198680</td>\n",
       "      <td>0.650171</td>\n",
       "      <td>125.113392</td>\n",
       "      <td>5.052459</td>\n",
       "      <td>0.642574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge (alpha=1)</td>\n",
       "      <td>123.384207</td>\n",
       "      <td>5.198685</td>\n",
       "      <td>0.650171</td>\n",
       "      <td>125.113421</td>\n",
       "      <td>5.052463</td>\n",
       "      <td>0.642574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge (alpha=10)</td>\n",
       "      <td>123.384207</td>\n",
       "      <td>5.198737</td>\n",
       "      <td>0.650171</td>\n",
       "      <td>125.113705</td>\n",
       "      <td>5.052513</td>\n",
       "      <td>0.642573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge (alpha=100)</td>\n",
       "      <td>123.384213</td>\n",
       "      <td>5.199261</td>\n",
       "      <td>0.650171</td>\n",
       "      <td>125.116548</td>\n",
       "      <td>5.053003</td>\n",
       "      <td>0.642565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso (alpha=0.01)</td>\n",
       "      <td>123.384210</td>\n",
       "      <td>5.198858</td>\n",
       "      <td>0.650171</td>\n",
       "      <td>125.115332</td>\n",
       "      <td>5.052626</td>\n",
       "      <td>0.642568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasso (alpha=0.1)</td>\n",
       "      <td>123.384607</td>\n",
       "      <td>5.201739</td>\n",
       "      <td>0.650169</td>\n",
       "      <td>125.134495</td>\n",
       "      <td>5.055348</td>\n",
       "      <td>0.642514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lasso (alpha=1)</td>\n",
       "      <td>123.421151</td>\n",
       "      <td>5.229507</td>\n",
       "      <td>0.650066</td>\n",
       "      <td>125.338356</td>\n",
       "      <td>5.083092</td>\n",
       "      <td>0.641931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lasso (alpha=10)</td>\n",
       "      <td>126.141514</td>\n",
       "      <td>5.540418</td>\n",
       "      <td>0.642353</td>\n",
       "      <td>128.902136</td>\n",
       "      <td>5.408803</td>\n",
       "      <td>0.631750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lasso (alpha=100)</td>\n",
       "      <td>234.655937</td>\n",
       "      <td>11.285489</td>\n",
       "      <td>0.334683</td>\n",
       "      <td>233.064336</td>\n",
       "      <td>11.258653</td>\n",
       "      <td>0.334178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model   Train MSE  Train MAE  Train R^2    Test MSE  \\\n",
       "0    Linear Regression  123.384207   5.198679   0.650171  125.113389   \n",
       "1   Ridge (alpha=0.01)  123.384207   5.198679   0.650171  125.113389   \n",
       "2    Ridge (alpha=0.1)  123.384207   5.198680   0.650171  125.113392   \n",
       "3      Ridge (alpha=1)  123.384207   5.198685   0.650171  125.113421   \n",
       "4     Ridge (alpha=10)  123.384207   5.198737   0.650171  125.113705   \n",
       "5    Ridge (alpha=100)  123.384213   5.199261   0.650171  125.116548   \n",
       "6   Lasso (alpha=0.01)  123.384210   5.198858   0.650171  125.115332   \n",
       "7    Lasso (alpha=0.1)  123.384607   5.201739   0.650169  125.134495   \n",
       "8      Lasso (alpha=1)  123.421151   5.229507   0.650066  125.338356   \n",
       "9     Lasso (alpha=10)  126.141514   5.540418   0.642353  128.902136   \n",
       "10   Lasso (alpha=100)  234.655937  11.285489   0.334683  233.064336   \n",
       "\n",
       "     Test MAE  Test R^2  \n",
       "0    5.052458  0.642574  \n",
       "1    5.052458  0.642574  \n",
       "2    5.052459  0.642574  \n",
       "3    5.052463  0.642574  \n",
       "4    5.052513  0.642573  \n",
       "5    5.053003  0.642565  \n",
       "6    5.052626  0.642568  \n",
       "7    5.055348  0.642514  \n",
       "8    5.083092  0.641931  \n",
       "9    5.408803  0.631750  \n",
       "10  11.258653  0.334178  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OUTLIER DATA\n",
    "rows = []\n",
    "\n",
    "# Get linear regression metrics. \n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "rows.append(compute_metrics(lin_reg, \"Linear Regression\"))\n",
    "\n",
    "#Get Lasso and Ridge regression metrics per alpha value. \n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    rows.append(compute_metrics(ridge, \"Ridge\", alpha))\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    rows.append(compute_metrics(lasso, \"Lasso\", alpha))\n",
    "\n",
    "#Print results in DF. \n",
    "results = pd.DataFrame(rows)\n",
    "print(\"Models trained w/ Outliers\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models trained w/out Outliers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Train R^2</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>59.887427</td>\n",
       "      <td>4.069898</td>\n",
       "      <td>0.806996</td>\n",
       "      <td>40.098111</td>\n",
       "      <td>4.013913</td>\n",
       "      <td>0.866504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge (alpha=0.01)</td>\n",
       "      <td>59.887427</td>\n",
       "      <td>4.069898</td>\n",
       "      <td>0.806996</td>\n",
       "      <td>40.098110</td>\n",
       "      <td>4.013913</td>\n",
       "      <td>0.866504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge (alpha=0.1)</td>\n",
       "      <td>59.887427</td>\n",
       "      <td>4.069899</td>\n",
       "      <td>0.806996</td>\n",
       "      <td>40.098109</td>\n",
       "      <td>4.013914</td>\n",
       "      <td>0.866504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge (alpha=1)</td>\n",
       "      <td>59.887427</td>\n",
       "      <td>4.069907</td>\n",
       "      <td>0.806996</td>\n",
       "      <td>40.098097</td>\n",
       "      <td>4.013921</td>\n",
       "      <td>0.866504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge (alpha=10)</td>\n",
       "      <td>59.887428</td>\n",
       "      <td>4.069987</td>\n",
       "      <td>0.806996</td>\n",
       "      <td>40.097978</td>\n",
       "      <td>4.013988</td>\n",
       "      <td>0.866504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge (alpha=100)</td>\n",
       "      <td>59.887473</td>\n",
       "      <td>4.070784</td>\n",
       "      <td>0.806995</td>\n",
       "      <td>40.096827</td>\n",
       "      <td>4.014657</td>\n",
       "      <td>0.866508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso (alpha=0.01)</td>\n",
       "      <td>59.887430</td>\n",
       "      <td>4.069882</td>\n",
       "      <td>0.806996</td>\n",
       "      <td>40.100439</td>\n",
       "      <td>4.013892</td>\n",
       "      <td>0.866496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasso (alpha=0.1)</td>\n",
       "      <td>59.887950</td>\n",
       "      <td>4.072011</td>\n",
       "      <td>0.806994</td>\n",
       "      <td>40.119531</td>\n",
       "      <td>4.015638</td>\n",
       "      <td>0.866433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lasso (alpha=1)</td>\n",
       "      <td>59.944088</td>\n",
       "      <td>4.096430</td>\n",
       "      <td>0.806813</td>\n",
       "      <td>40.358763</td>\n",
       "      <td>4.037275</td>\n",
       "      <td>0.865636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lasso (alpha=10)</td>\n",
       "      <td>64.728845</td>\n",
       "      <td>4.580677</td>\n",
       "      <td>0.791393</td>\n",
       "      <td>46.589091</td>\n",
       "      <td>4.526738</td>\n",
       "      <td>0.844894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lasso (alpha=100)</td>\n",
       "      <td>174.788910</td>\n",
       "      <td>10.318320</td>\n",
       "      <td>0.436693</td>\n",
       "      <td>157.457130</td>\n",
       "      <td>10.274340</td>\n",
       "      <td>0.475788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model   Train MSE  Train MAE  Train R^2    Test MSE  \\\n",
       "0    Linear Regression   59.887427   4.069898   0.806996   40.098111   \n",
       "1   Ridge (alpha=0.01)   59.887427   4.069898   0.806996   40.098110   \n",
       "2    Ridge (alpha=0.1)   59.887427   4.069899   0.806996   40.098109   \n",
       "3      Ridge (alpha=1)   59.887427   4.069907   0.806996   40.098097   \n",
       "4     Ridge (alpha=10)   59.887428   4.069987   0.806996   40.097978   \n",
       "5    Ridge (alpha=100)   59.887473   4.070784   0.806995   40.096827   \n",
       "6   Lasso (alpha=0.01)   59.887430   4.069882   0.806996   40.100439   \n",
       "7    Lasso (alpha=0.1)   59.887950   4.072011   0.806994   40.119531   \n",
       "8      Lasso (alpha=1)   59.944088   4.096430   0.806813   40.358763   \n",
       "9     Lasso (alpha=10)   64.728845   4.580677   0.791393   46.589091   \n",
       "10   Lasso (alpha=100)  174.788910  10.318320   0.436693  157.457130   \n",
       "\n",
       "     Test MAE  Test R^2  \n",
       "0    4.013913  0.866504  \n",
       "1    4.013913  0.866504  \n",
       "2    4.013914  0.866504  \n",
       "3    4.013921  0.866504  \n",
       "4    4.013988  0.866504  \n",
       "5    4.014657  0.866508  \n",
       "6    4.013892  0.866496  \n",
       "7    4.015638  0.866433  \n",
       "8    4.037275  0.865636  \n",
       "9    4.526738  0.844894  \n",
       "10  10.274340  0.475788  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NON OUTLIER DATA\n",
    "\n",
    "#Create DF and test/train splits of cleaned data\n",
    "DATA_PATH = \"usina.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "X = df.drop(\"PE\", axis=1)\n",
    "y = df[\"PE\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Get linear regression metrics. \n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "rows.append(compute_metrics(lin_reg, \"Linear Regression\"))\n",
    "\n",
    "# Get Ridge and Lasso regression metrics for alpha values. \n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    rows.append(compute_metrics(ridge, \"Ridge\", alpha))\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    rows.append(compute_metrics(lasso, \"Lasso\", alpha))\n",
    "\n",
    "# Display results in DF. \n",
    "results = pd.DataFrame(rows)\n",
    "print(\"Models trained w/out Outliers\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** Outliers do affect both train and test error. When the outliers were removed, both errors decreased and the R^2 improved for both train and test sets.\n",
    "\n",
    "Both datasets showed similar generalization, but the dataset without outliers performed slightly better. The MAE for the dataset with outliers increased more from train to test, indicating that removing outliers improved generalization.\n",
    "\n",
    "Comparing models, standard linear regression, Ridge, and Lasso performed similarly overall. Ridge and Lasso did not noticeably outperform linear regression. For Lasso, the coefficients changed slightly for the largest alpha values, but this trend was consistent across both datasets and generally did not improve performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: ##\n",
    "**Method choice and Scaling Decision**: For this question, I will use Linear Regression (OLS) with Statsmodels. I am not using Ridge or Lasso because they shrink coefficients, which would make them less interpretable and less reliable for understanding the true effect of each predictor. I chose Statsmodels because it provides built-in p-values, t-statistics, and confidence intervals, allowing me to assess the statistical reliability of each coefficient.\n",
    "\n",
    "I will not scale either the independent variables (IVs) or the dependent variable (DV). Scaling would change the magnitude of the coefficients, and since I am interested in the coefficients in their original units, scaling would reduce their interpretability and reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>t_value</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AT</th>\n",
       "      <td>-1.152841</td>\n",
       "      <td>-51.515147</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>-0.373753</td>\n",
       "      <td>-31.956657</td>\n",
       "      <td>5.272828e-213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.444891</td>\n",
       "      <td>23.392484</td>\n",
       "      <td>9.877819e-118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>47.784508</td>\n",
       "      <td>2.447421</td>\n",
       "      <td>1.440612e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RH</th>\n",
       "      <td>-0.017546</td>\n",
       "      <td>-2.183688</td>\n",
       "      <td>2.900939e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coefficient    t_value        p_value\n",
       "AT       -1.152841 -51.515147   0.000000e+00\n",
       "V        -0.373753 -31.956657  5.272828e-213\n",
       "AP        0.444891  23.392484  9.877819e-118\n",
       "const    47.784508   2.447421   1.440612e-02\n",
       "RH       -0.017546  -2.183688   2.900939e-02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WITH STATSMODEL\n",
    "\n",
    "X_sm = sm.add_constant(X)\n",
    "\n",
    "#Fit model\n",
    "ols_model = sm.OLS(y, X_sm).fit()\n",
    "\n",
    "#Create results dataframe of coefficients. \n",
    "results_df = pd.DataFrame({\n",
    "    \"Coefficient\": ols_model.params,\n",
    "    \"t_value\": ols_model.tvalues,\n",
    "    \"p_value\": ols_model.pvalues\n",
    "})\n",
    "\n",
    "results_df = results_df.reindex(results_df[\"t_value\"].abs().sort_values(ascending=False).index)\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most reliable coefficient:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Coefficient    -1.152841\n",
       "t_value       -51.515147\n",
       "p_value         0.000000\n",
       "Name: AT, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Least reliable coefficient:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Coefficient   -0.017546\n",
       "t_value       -2.183688\n",
       "p_value        0.029009\n",
       "Name: RH, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "most_reliable = results_df.iloc[0]  # largest absolute t-value\n",
    "least_reliable = results_df.iloc[-1]  # smallest absolute t-value\n",
    "\n",
    "print(\"Most reliable coefficient:\")\n",
    "display(most_reliable)\n",
    "\n",
    "print(\"\\nLeast reliable coefficient:\")\n",
    "display(least_reliable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most reliable coefficient was decided by the coefficient with the largest absolute t-value. The smallest t-value showed the least reliable coefficient. The above displays the t values of the each coefficient. \n",
    "The most reliable coefficent was the **Ambient Temperature**. The least reliable was the **Relative Humidity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: ##\n",
    "**Method choice and scaling decision**: I chose Lasso Regression because it performs automatic feature selection by shrinking some coefficients exactly to zero, making it well-suited for identifying the most and least important features. I used Scikit-learn because it provides efficient implementations of regularized models and integrates naturally with preprocessing tools like feature scaling.\n",
    "\n",
    "I would scale all independent variables but not the dependent variable. Scaling IVs is necessary because coefficient magnitude is used to assess feature importance, and without scaling, variables measured in larger units would appear artificially more important. Scaling ensures fair comparison and proper application of regularization. Scaling the DV is unnecessary since it does not affect relative feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda (alpha): 0.47148663634573945\n",
      "\n",
      "\n",
      "Coefficients:\n",
      " AT   -8.891647\n",
      "V    -5.653774\n",
      "AP    2.425466\n",
      "RH    0.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Most important feature: AT \n",
      "Least Important: RH\n"
     ]
    }
   ],
   "source": [
    "#Best Alpha Value Selection\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lasso\", LassoCV(\n",
    "        alphas=np.logspace(-4, 1, 50),\n",
    "        cv=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "best_alpha = pipeline.named_steps[\"lasso\"].alpha_\n",
    "print(\"Best lambda (alpha):\", best_alpha)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Finding coefficient values scaled. \n",
    "lasso = pipeline.named_steps[\"lasso\"]\n",
    "\n",
    "coefficients = pd.Series(\n",
    "    lasso.coef_,\n",
    "    index=X.columns\n",
    ")\n",
    "\n",
    "print(f\"Coefficients:\\n\", coefficients)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "#Largest and smallest absolute value of coeffficent. \n",
    "most_important = coefficients.abs().idxmax() #Largest coefficient value. \n",
    "\n",
    "least_important = coefficients.abs().idxmin() #Smallest coefficient value (Lasso shrinks unimportant)\n",
    "\n",
    "print(f\"Most important feature: {most_important} \\nLeast Important: {least_important}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance:** The most important feature is **Ambient Temperature** and the least important is **Ambient Pressure**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Lasso')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create alpha values from 10^-1 to 10^5 (100 values) and coefficient storage. \n",
    "alphas = np.logspace(-1, 5, 100)\n",
    "\n",
    "ridge_coefs = []\n",
    "lasso_coefs = []\n",
    "\n",
    "#For each alpha value, fit the model and find coefficients. \n",
    "for alpha in alphas:\n",
    "\n",
    "    ridge = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ridge\", Ridge(alpha=alpha))\n",
    "    ])\n",
    "\n",
    "    lasso = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lasso\", Lasso(alpha=alpha))\n",
    "    ])\n",
    "\n",
    "    ridge.fit(X_train, y_train)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    ridge_coefs.append(ridge.named_steps[\"ridge\"].coef_)\n",
    "    lasso_coefs.append(lasso.named_steps[\"lasso\"].coef_)\n",
    "\n",
    "ridge_coefs = np.array(ridge_coefs)\n",
    "lasso_coefs = np.array(lasso_coefs)\n",
    "\n",
    "#Plot alpha values vs coefficient values. \n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for j in range(ridge_coefs.shape[1]):\n",
    "    plt.plot(alphas, ridge_coefs[:, j])\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"λ\")\n",
    "plt.ylabel(\"Coefficients\")\n",
    "plt.title(\"Ridge\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for j in range(lasso_coefs.shape[1]):\n",
    "    plt.plot(alphas, lasso_coefs[:, j])\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"λ\")\n",
    "plt.ylabel(\"Coefficients\")\n",
    "plt.title(\"Lasso\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** In Ridge, the coefficients start to slowly shrink and converge towards 0 (but never 0). The coefficient that had a value of 0 even changed and then converged towards 0. In Lasso, the coefficients converge to 0 as the lambda increases, much faster. The coefficient with the smallest absolute value converges faster than the coefficients with larger absolute values, but by a lambda value of 10, all are converging, if not already converged. In Ridge, the convergence seems to be at the same pace regardless of absolute value of the coefficient. \n",
    "\n",
    "Ridge is better under multicollinearity because it shrinks correlated variables together without eliminating any (none are ever actually 0). Lasso may select one variable from a group and set the others to zero, which is less stable, since the IV's are all very correlated. \n",
    "\n",
    "Lasso is better for feature selection because it has built in feature 'selection' by shrinking those features which are not as important to 0. This introduces sparsity where only the important predictors remain (selected). "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
